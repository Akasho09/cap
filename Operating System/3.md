## SCHEDULING ALGORITHMS :
### Classification of Scheduling Algorithms
1. ðŸ”¹ Non-Preemptive
- Once CPU is allocated, process runs till completion or I/O wait
- Simple but poor responsiveness

2. ðŸ”¹ Preemptive
- CPU can be taken away by OS
- Better responsiveness, more complex

| **Metric**  | **Full Form**           | **Formula**                         | **Meaning (1-line)**            |
| ----------- | ----------------------- | ----------------------------------- | ------------------------------- |
| **AT**      | Arrival Time            | Given                               | Time when process enters system |
| **BT**      | Burst Time              | Given                               | CPU time required               |
| **CT**      | Completion Time         | From Gantt chart                    | Time when process finishes      |
| **TAT**     | Turnaround Time         | **CT âˆ’ AT**                         | Total time in system            |
| **WT**      | Waiting Time            | **TAT âˆ’ BT**<br>or **CT âˆ’ AT âˆ’ BT** | Time waiting in ready queue     |
| **RT**      | Response Time           | **First CPU Start âˆ’ AT**            | Time till first CPU response    |
| **Avg WT**  | Average Waiting Time    | Î£WT / n                             | Mean waiting time               |
| **Avg TAT** | Average Turnaround Time | Î£TAT / n                            | Mean turnaround time            |
| **Avg RT**  | Average Response Time   | Î£RT / n                             | Mean response time              |

### 
1. 1ï¸âƒ£ First Come First Serve (FCFS)
- Type: Non-preemptive
- How it works
    - Processes executed in order of arrival
- Advantages
    - âœ… Simple
    - âœ… No starvation
- Disadvantages
    - âŒ Convoy effect : Convoy Effect is a situation in CPU scheduling where many short processes wait behind one long CPU-bound process, causing poor CPU utilization and high waiting time. 
    - âŒ Poor average waiting time
- ðŸ“Œ Used in: Batch systems (rare today)

2. 2ï¸âƒ£ Shortest Job First (SJF)
- Type: Non-preemptive
- How it works
    - Process with smallest CPU burst executes first
- Advantages
- âœ… Minimum average waiting time (optimal)
- Disadvantages
    - âŒ Burst time prediction needed
    - âŒ Starvation possible

3. 3ï¸âƒ£ Shortest Remaining Time First (SRTF)
- Type: Preemptive version of SJF
- How it works
    - Process with least remaining time runs
    - New shorter job can preempt running process
- Advantages
- âœ… Best response time
- Disadvantages
    - âŒ High overhead
    - âŒ Starvation

4. 4ï¸âƒ£ Priority Scheduling
- Type: Preemptive / Non-preemptive
- How it works
    - Highest-priority process runs first
- Advantages
    - âœ… Important tasks handled first
- Disadvantages
    - âŒ Starvation of low-priority jobs
    - ðŸ“Œ Solution: Aging : Aging gradually increases the priority of a process the longer it waits in the ready queue.
    - Also Convoy effect.

5. 5ï¸âƒ£ Round Robin (RR)
- Type: Preemptive
- How it works
    - Each process gets fixed time quantum
- After quantum expires â†’ moved to back of queue(FCFS).
- Advantages
    - âœ… Fair.
    - âœ… Good response time.
- Disadvantages
    - âŒ Context switching overhead
- ðŸ“Œ Used in: Time-sharing systems

6. 6ï¸âƒ£ Multilevel Queue Scheduling
- Multilevel Queue Scheduling is a CPU scheduling technique where the ready queue is permanently divided into multiple queues, each for a different type of process.
- No movement between queues
| Queue        | Type of Process          | Scheduling Used     |
| ------------ | ------------------------ | ------------------- |
| Q1 (Highest) | System processes         | Preemptive Priority |
| Q2           | Interactive / Foreground | Round Robin         |
| Q3           | Batch / Background       | FCFS                |
> ðŸ‘‰ CPU first serves Q1, then Q2, then Q3

7. 7ï¸âƒ£ Multilevel Feedback Queue (MLFQ)
- Most powerful & modern
- How it works
    - Processes can move between queues
    - Priority changes based on behavior
- ðŸ‘‰ It is designed to combine priority scheduling + Round Robin + aging.
![alt text](image-2.png)

### Working :
- New processes start in the highest-priority queue
- If a process:
    - Uses too much CPU â†’ it is demoted
    - Waits too long â†’ it is promoted (aging)
- Thus, priorities are dynamic
- Advantages
    - âœ… No starvation
    - âœ… Adaptive
ðŸ“Œ Used by: Modern OSs

| Algorithm   | Preemptive | Starvation | Use Case     |
| ----------- | ---------- | ---------- | ------------ |
| FCFS        | âŒ          | âŒ          | Batch        |
| SJF         | âŒ          | âœ…          | Short jobs   |
| SRTF        | âœ…          | âœ…          | Interactive  |
| Priority    | Both       | âœ…          | Real-time    |
| Round Robin | âœ…          | âŒ          | Time-sharing |
| MLFQ        | âœ…          | âŒ          | Modern OS    |

### Which OS uses what?
- Linux â†’ CFS (MLFQ-like)
- Windows â†’ Priority + RR
- macOS â†’ Priority-based, adaptive

# Thread Context Scheduling (Thread Context Switching)
- Thread context scheduling is the process by which the CPU switches execution from one thread to another by saving the current threadâ€™s state and restoring another threadâ€™s state.
- ðŸ‘‰ It allows multiple threads to share the CPU efficiently.
- A thread context includes:
    - Program Counter (PC)
    - CPU registers
    - Stack pointer
    - Thread state (Running, Ready, Waiting)
- NO Memory pointers as threads share same memory.
- This information is stored in a Thread Control Block (TCB).

| Feature              | Thread Switch  | Process Switch  |
| -------------------- | -------------- | --------------- |
| Memory Space         | Shared         | Different       |
| Speed                | Faster         | Slower          |
| Overhead             | Low            | High            |
| Address Space Change | No             | Yes             |
| Used in              | Multithreading | Multiprocessing |
| Cache Flushing       | No             | Yes             |

## Concurrency
- Concurrency means multiple tasks make progress during the same time period, but not necessarily at the same instant.
    - One CPU
    - Tasks take turns using the CPU
    - Achieved through context switching

| Feature         | Concurrency          | Parallelism              |
| --------------- | -------------------- | ------------------------ |
| Execution       | Interleaved          | Simultaneous             |
| CPU Requirement | Single or multi-core | Multi-core required      |
| Goal            | Responsiveness       | Speed & performance      |
| Implementation  | Time-slicing         | Multiple cores           |
| Example         | Multitasking OS      | Parallel data processing |

## Race Condition (Operating Systems)
- A race condition occurs when two or more threads/processes access shared data at the same time, and the final result depends on the order of execution.
- The output becomes unpredictable because operations are not synchronized.
> A race condition occurs when multiple processes or threads try to read and write shared data concurrently, and the final result depends on the timing of execution.

### âœ… Solutions to the Critical Section Problem
- The critical section problem occurs when multiple processes/threads access shared data at the same time, causing race conditions.
- A correct solution must satisfy three conditions:
- âœ… Requirements of a Correct Solution
1. **Mutual Exclusion**â€“ Only one process enters the critical section at a time
2. **Progress** â€“ If no process is in the critical section, one must be allowed to enter
3. **Bounded Waiting** â€“ No process should wait forever

### Does a Single Flag Solve the Critical Section Problem?
- NO 
```c
int flag = 0;   // 0 = free, 1 = busy

Process P1:
while (flag == 1);
flag = 1;
// critical section
flag = 0;

Process P2:
while (flag == 1);
flag = 1;
// critical section
flag = 0;
```

### How to prevent Race Condition :
1. Atomic Operation
- An atomic operation is an operation that executes completely or not at all â€” it cannot be interrupted by other threads or processes.
- Common Atomic Operations
    - test-and-set
    - compare-and-swap (CAS)
    - fetch-and-add
    - atomic increment / decrement
- Used heavily in:
    - Locks
    - Semaphores
    - Spinlocks
    - Mutexes
> An atomic operation is an indivisible operation that completes entirely without interruption, ensuring safe access to shared data.

2. Petersonâ€™s Algorithm
- A single flag fails because both processes can check the flag before either sets it, leading to a race condition.
- ðŸ”¹ Idea Behind Two Flags
- Each process:
    - Announces its intention to enter the critical section
    - Gives priority to the other process
    - Waits if the other process also wants to enter
- This guarantees:
    - Mutual exclusion
    - Progress
    - Bounded waiting
```c
boolean flag[2];
int turn;

Process P0:
flag[0] = true;
turn = 1;
while (flag[1] && turn == 1);
   // critical section
flag[0] = false;

Process P1:
flag[1] = true;
turn = 0;
while (flag[0] && turn == 0);
   // critical section
flag[1] = false;
```
- Disadvantages of Peterson:
| Limitation             | Explanation              |
| ---------------------- | ------------------------ |
| Limited to 2 processes | Not scalable             |
| Busy waiting           | Wastes CPU               |
| Hardware assumptions   | Not valid on modern CPUs |
| No priority handling   | Can cause inefficiency   |
| Not practical          | Used only for theory     |


3. Mutual Exclusion (Locks)
```yml
mutex.lock();
### critical section
mutex.unlock();
```
- Disadvantges of Locks:
| Disadvantage         | Explanation                       |
| -------------------- | --------------------------------- |
| Deadlock             | Circular waiting for locks        |
| Starvation           | Some threads never get CPU        |
| Priority inversion   | Low-priority blocks high-priority |
| Busy waiting         | Wastes CPU cycles                 |
| Poor scalability     | Limits parallelism                |
| Debugging difficulty | Hard to reproduce issues          |

### Condition Variables
- Locks alone only provide mutual exclusion, but they cannot make a thread wait efficiently for a condition.
- Condition variables allow:
    - Threads to sleep (wait) until a condition is satisfied
    - Another thread to signal when the condition becomes true
- This avoids busy waiting.
| Operation     | Meaning                               |
| ------------- | ------------------------------------- |
| `wait()`      | Releases lock & sleeps until signaled |
| `signal()`    | Wakes one waiting thread              |
| `broadcast()` | Wakes all waiting threads             |
```c
lock(mutex);
while (condition == false) {
    wait(condition, mutex);
}
// critical section
unlock(mutex);
```

3. Semaphores
- Control access to shared resources.
