## SCHEDULING ALGORITHMS :
### Classification of Scheduling Algorithms
1. ðŸ”¹ Non-Preemptive
- Once CPU is allocated, process runs till completion or I/O wait
- Simple but poor responsiveness

2. ðŸ”¹ Preemptive
- CPU can be taken away by OS
- Better responsiveness, more complex

| **Metric**  | **Full Form**           | **Formula**                         | **Meaning (1-line)**            |
| ----------- | ----------------------- | ----------------------------------- | ------------------------------- |
| **AT**      | Arrival Time            | Given                               | Time when process enters system |
| **BT**      | Burst Time              | Given                               | CPU time required               |
| **CT**      | Completion Time         | From Gantt chart                    | Time when process finishes      |
| **TAT**     | Turnaround Time         | **CT âˆ’ AT**                         | Total time in system            |
| **WT**      | Waiting Time            | **TAT âˆ’ BT**<br>or **CT âˆ’ AT âˆ’ BT** | Time waiting in ready queue     |
| **RT**      | Response Time           | **First CPU Start âˆ’ AT**            | Time till first CPU response    |
| **Avg WT**  | Average Waiting Time    | Î£WT / n                             | Mean waiting time               |
| **Avg TAT** | Average Turnaround Time | Î£TAT / n                            | Mean turnaround time            |
| **Avg RT**  | Average Response Time   | Î£RT / n                             | Mean response time              |

### 
1. 1ï¸âƒ£ First Come First Serve (FCFS)
- Type: Non-preemptive
- How it works
    - Processes executed in order of arrival
- Advantages
    - âœ… Simple
    - âœ… No starvation
- Disadvantages
    - âŒ Convoy effect : Convoy Effect is a situation in CPU scheduling where many short processes wait behind one long CPU-bound process, causing poor CPU utilization and high waiting time. 
    - âŒ Poor average waiting time
- ðŸ“Œ Used in: Batch systems (rare today)

2. 2ï¸âƒ£ Shortest Job First (SJF)
- Type: Non-preemptive
- How it works
    - Process with smallest CPU burst executes first
- Advantages
- âœ… Minimum average waiting time (optimal)
- Disadvantages
    - âŒ Burst time prediction needed
    - âŒ Starvation possible

3. 3ï¸âƒ£ Shortest Remaining Time First (SRTF)
- Type: Preemptive version of SJF
- How it works
    - Process with least remaining time runs
    - New shorter job can preempt running process
- Advantages
- âœ… Best response time
- Disadvantages
    - âŒ High overhead
    - âŒ Starvation

4. 4ï¸âƒ£ Priority Scheduling
- Type: Preemptive / Non-preemptive
- How it works
    - Highest-priority process runs first
- Advantages
    - âœ… Important tasks handled first
- Disadvantages
    - âŒ Starvation of low-priority jobs
    - ðŸ“Œ Solution: Aging : Aging gradually increases the priority of a process the longer it waits in the ready queue.
    - Also Convoy effect.

5. 5ï¸âƒ£ Round Robin (RR)
- Type: Preemptive
- How it works
    - Each process gets fixed time quantum
- After quantum expires â†’ moved to back of queue(FCFS).
- Advantages
    - âœ… Fair.
    - âœ… Good response time.
- Disadvantages
    - âŒ Context switching overhead
- ðŸ“Œ Used in: Time-sharing systems

6. 6ï¸âƒ£ Multilevel Queue Scheduling
- Multilevel Queue Scheduling is a CPU scheduling technique where the ready queue is permanently divided into multiple queues, each for a different type of process.
- No movement between queues
| Queue        | Type of Process          | Scheduling Used     |
| ------------ | ------------------------ | ------------------- |
| Q1 (Highest) | System processes         | Preemptive Priority |
| Q2           | Interactive / Foreground | Round Robin         |
| Q3           | Batch / Background       | FCFS                |
> ðŸ‘‰ CPU first serves Q1, then Q2, then Q3

7. 7ï¸âƒ£ Multilevel Feedback Queue (MLFQ)
- Most powerful & modern
- How it works
    - Processes can move between queues
    - Priority changes based on behavior
- ðŸ‘‰ It is designed to combine priority scheduling + Round Robin + aging.
![alt text](image-2.png)

### Working :
- New processes start in the highest-priority queue
- If a process:
    - Uses too much CPU â†’ it is demoted
    - Waits too long â†’ it is promoted (aging)
- Thus, priorities are dynamic
- Advantages
    - âœ… No starvation
    - âœ… Adaptive
ðŸ“Œ Used by: Modern OSs

| Algorithm   | Preemptive | Starvation | Use Case     |
| ----------- | ---------- | ---------- | ------------ |
| FCFS        | âŒ          | âŒ          | Batch        |
| SJF         | âŒ          | âœ…          | Short jobs   |
| SRTF        | âœ…          | âœ…          | Interactive  |
| Priority    | Both       | âœ…          | Real-time    |
| Round Robin | âœ…          | âŒ          | Time-sharing |
| MLFQ        | âœ…          | âŒ          | Modern OS    |

### Which OS uses what?
- Linux â†’ CFS (MLFQ-like)
- Windows â†’ Priority + RR
- macOS â†’ Priority-based, adaptive

# Thread Context Scheduling (Thread Context Switching)
- Thread context scheduling is the process by which the CPU switches execution from one thread to another by saving the current threadâ€™s state and restoring another threadâ€™s state.
- ðŸ‘‰ It allows multiple threads to share the CPU efficiently.
- A thread context includes:
    - Program Counter (PC)
    - CPU registers
    - Stack pointer
    - Thread state (Running, Ready, Waiting)
- NO Memory pointers as threads share same memory.
- This information is stored in a Thread Control Block (TCB).

| Feature              | Thread Switch  | Process Switch  |
| -------------------- | -------------- | --------------- |
| Memory Space         | Shared         | Different       |
| Speed                | Faster         | Slower          |
| Overhead             | Low            | High            |
| Address Space Change | No             | Yes             |
| Used in              | Multithreading | Multiprocessing |
| Cache Flushing       | No             | Yes             |

## Concurrency
- Concurrency means multiple tasks make progress during the same time period, but not necessarily at the same instant.
    - One CPU
    - Tasks take turns using the CPU
    - Achieved through context switching

| Feature         | Concurrency          | Parallelism              |
| --------------- | -------------------- | ------------------------ |
| Execution       | Interleaved          | Simultaneous             |
| CPU Requirement | Single or multi-core | Multi-core required      |
| Goal            | Responsiveness       | Speed & performance      |
| Implementation  | Time-slicing         | Multiple cores           |
| Example         | Multitasking OS      | Parallel data processing |

## Race Condition (Operating Systems)
- A race condition occurs when two or more threads/processes access shared data at the same time, and the final result depends on the order of execution.
- The output becomes unpredictable because operations are not synchronized.
> A race condition occurs when multiple processes or threads try to read and write shared data concurrently, and the final result depends on the timing of execution.

### âœ… Solutions to the Critical Section Problem
- The critical section problem occurs when multiple processes/threads access shared data at the same time, causing race conditions.
- A correct solution must satisfy three conditions:
- âœ… Requirements of a Correct Solution
1. **Mutual Exclusion**â€“ Only one process enters the critical section at a time
2. **Progress** â€“ If no process is in the critical section, one must be allowed to enter
3. **Bounded Waiting** â€“ No process should wait forever

### Does a Single Flag Solve the Critical Section Problem?
- NO 
```c
int flag = 0;   // 0 = free, 1 = busy

Process P1:
while (flag == 1);
flag = 1;
// critical section
flag = 0;

Process P2:
while (flag == 1);
flag = 1;
// critical section
flag = 0;
```

### How to prevent Race Condition :
1. Atomic Operation
- An atomic operation is an operation that executes completely or not at all â€” it cannot be interrupted by other threads or processes.
- Common Atomic Operations
    - test-and-set
    - compare-and-swap (CAS)
    - fetch-and-add
    - atomic increment / decrement
- Used heavily in:
    - Locks
    - Semaphores
    - Spinlocks
    - Mutexes
> An atomic operation is an indivisible operation that completes entirely without interruption, ensuring safe access to shared data.

2. Petersonâ€™s Algorithm
- A single flag fails because both processes can check the flag before either sets it, leading to a race condition.
- ðŸ”¹ Idea Behind Two Flags
- Each process:
    - Announces its intention to enter the critical section
    - Gives priority to the other process
    - Waits if the other process also wants to enter
- This guarantees:
    - Mutual exclusion
    - Progress
    - Bounded waiting
```c
boolean flag[2];
int turn;

Process P0:
flag[0] = true;
turn = 1;
while (flag[1] && turn == 1);
   // critical section
flag[0] = false;

Process P1:
flag[1] = true;
turn = 0;
while (flag[0] && turn == 0);
   // critical section
flag[1] = false;
```
- Disadvantages of Peterson:
| Limitation             | Explanation              |
| ---------------------- | ------------------------ |
| Limited to 2 processes | Not scalable             |
| Busy waiting           | Wastes CPU               |
| Hardware assumptions   | Not valid on modern CPUs |
| No priority handling   | Can cause inefficiency   |
| Not practical          | Used only for theory     |


3. Mutual Exclusion (Locks)
```yml
mutex.lock();
### critical section
mutex.unlock();
```
- Disadvantges of Locks:
| Disadvantage         | Explanation                       |
| -------------------- | --------------------------------- |
| Deadlock             | Circular waiting for locks        |
| Starvation           | Some threads never get CPU        |
| Priority inversion   | Low-priority blocks high-priority |
| Busy waiting         | Wastes CPU cycles                 |
| Poor scalability     | Limits parallelism                |
| Debugging difficulty | Hard to reproduce issues          |

### Condition Variables
- Locks alone only provide mutual exclusion, but they cannot make a thread wait efficiently for a condition.
- Condition variables allow:
    - Threads to sleep (wait) until a condition is satisfied
    - Another thread to signal when the condition becomes true
- This avoids busy waiting.
| Operation     | Meaning                               |
| ------------- | ------------------------------------- |
| `wait()`      | Releases lock & sleeps until signaled |
| `signal()`    | Wakes one waiting thread              |
| `broadcast()` | Wakes all waiting threads             |
```c
lock(mutex);
while (condition == false) {
    wait(condition, mutex);
}
// critical section
unlock(mutex);
```

3. Semaphores
- A semaphore is a synchronization tool used to control access to shared resources by multiple processes or threads.
- ðŸ‘‰ It is basically a counter with two atomic operations:
- wait() / P() â†’ decrease value i.e wait(){s--;}
- signal() / V() â†’ increase value i.e signal(){s++;}
| Operation  | Description                             |
| ---------- | --------------------------------------- |
| `wait()`   | Decrements value; blocks if value < 0   |
| `signal()` | Increments value; wakes waiting process |

#### ðŸ”¹ Types of Semaphores
1. 1ï¸âƒ£ Binary Semaphore (Mutex)
- Value can be 0 or 1
- Used for mutual exclusion
```c
wait(mutex);
// critical section
signal(mutex);
```
- Only one process enters critical section
- âŒ No counting capability
- Binary Semaphore is equi to Locks

2. 2ï¸âƒ£ Counting Semaphore
- Value can be any non-negative integer
- Controls access to multiple instances of a resource
```c
semaphore S = 3;   // 3 identical resources
```
> If 3 threads acquire it â†’ next thread must wait.

| Feature         | Semaphore         | Mutex            |
| --------------- | ----------------- | ---------------- |
| Value           | Integer           | Binary           |
| Ownership       | No owner          | Owner-based      |
| Multiple access | Yes               | No               |
| Use case        | Resource counting | Mutual exclusion |

## Classical Problems in Operating Systems (Synchronization Problems)

1. 1ï¸âƒ£ Producerâ€“Consumer Problem
- One or more producers produce data
- One or more consumers consume data
- Shared buffer has limited size
- In this problem, we have:
    - Producers: Generate data items and place them in a shared buffer.
    - Consumers: Remove and process data items from the buffer.
- The main challenge is to ensure:
    - A producer does not add data to a full buffer.
    - A consumer does not remove data from an empty buffer.
    - Multiple producers and consumers do not access the buffer simultaneously, preventing race conditions.
```yml
Problem Statement
Consider a fixed-size buffer shared between a producer and a consumer.

The producer generates an item and places it in the buffer.
The consumer removes an item from the buffer.
> The buffer is the critical section. At any moment:

A producer cannot place an item if the buffer is full.
A consumer cannot remove an item if the buffer is empty.
```
- To manage this, we use three semaphores:
1. mutex â€“ ensures mutual exclusion when accessing the buffer.
2. full â€“ counts the number of filled slots in the buffer.
3. empty â€“ counts the number of empty slots in the buffer.

```cpp
mutex = 1;    // binary semaphore for mutual exclusion
full = 0;     // initially no filled slots
empty = n;    // buffer size

## Producer
do {
    // Produce an item
    wait(empty);    // Check for empty slot
    wait(mutex);    // Enter critical section
    // Place item in buffer
    signal(mutex);  // Exit critical section
    signal(full);   // Increase number of full slots
}while(1);

## Consumer 
do {
    wait(full);
    wait(mutex);
    // critical section
    signal(empty);
    signal(mutex);
}while(1);
```

2. 2ï¸âƒ£ Readersâ€“Writers Problem
- Multiple readers can read simultaneously
- Writer needs exclusive access
- Avoid writer starvation
- ðŸ”¹ Types:
    - Reader Priority â€“ readers favored
    - Writer Priority â€“ writers favored
- Fair solution â€“ no starvation
- ðŸ“Œ Used in databases, file systems

```yml
ðŸ“Œ Problem Statement

There is a shared data resource:
Readers â†’ Only read the data (do NOT modify it)
Writers â†’ Modify (write/update) the data

â— Challenge:
Multiple readers can read simultaneously.
Only one writer can access the resource at a time.
No reader should read while a writer is writing.
```

### ðŸ” Example (Readersâ€“Priority using Semaphores)
```cpp
semaphore mutex = 1;   // Protects read_count
semaphore wrt = 1;     // Controls writing
int read_count = 0;

Writer() {
    wait(wrt);
    // WRITING...
    signal(wrt);
}

Reader() {
    wait(mutex);
    read_count++;
    if (read_count == 1) wait(wrt);     // First reader locks writer
    signal(mutex);

    // READING...

    wait(mutex);
    read_count--;
    if (read_count == 0) signal(wrt);   // Last reader releases writer
    signal(mutex);
}
```

3. 3ï¸âƒ£ Dining Philosophers Problem
- The Dining Philosopher Problem is a classic synchronization problem introduced by Edsger Dijkstra in 1965.
```yml
Problem Statement
K philosophers sit around a circular table.
Each philosopher alternates between thinking and eating.
There is one chopstick between each philosopher (total K chopsticks).
A philosopher must pick up two chopsticks (left and right) to eat.
Only one philosopher can use a chopstick at a time.
```
> The challenge: Design a synchronization mechanism so that philosophers can eat without causing deadlock (all waiting forever) or starvation (some never get a chance to eat).

- Issues:
    - Deadlock
    - Starvation
- Solutions:
    - Limit number of philosophers eating
    - Resource hierarchy
    - Asymmetric pickup
    - Semaphore solution
```c
semaphore chopstick[5] = {1,1,1,1,1};

Philosopher(i):
while(true) {
   think();
   wait(chopstick[i]);             // pick left chopstick
   wait(chopstick[(i+1)%5]);       // pick right chopstick

   eat();

   signal(chopstick[i]);           // put left chopstick
   signal(chopstick[(i+1)%5]);     // put right chopstick
}
```
> STILL DEADLOCK CONDITION OCCOURS => IF ALL PICK THEIR RIGHT => DEADLOCK
#### Solutions:
1. Only 4 or N-1 Philospers sit on table
2. Philospher only pick chopstick if both are available
3. Odd Philosper picks Left and Even picks Right 

