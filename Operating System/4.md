## Deadlock
- A deadlock is a situation in which two or more processes are permanently blocked because each process is holding a resource and waiting for another resource held by another process.
> â€œEveryone waits forever, and nothing moves.â€

### ğŸ” Classic Example
- Process P1 holds Resource R1 and waits for R2
- Process P2 holds Resource R2 and waits for R1
> â¡ï¸ Neither can proceed â†’ Deadlock

### ğŸ”’ Necessary Conditions for Deadlock (Coffman Conditions)
> All four must occur simultaneously:

1. 1ï¸âƒ£ Mutual Exclusion
- At least one resource must be **non-shareable**(which means that only one process can use the resource at any given time)
ğŸ§  Example: Printer, File, Mutex

2. 2ï¸âƒ£ Hold and Wait
- A process holds one resource while waiting for another

3. 3ï¸âƒ£ No Preemption
- Resources cannot be forcibly taken from a process

4. 4ï¸âƒ£ Circular Wait
- A circular chain exists in RAG(Resource Allocation Graph)
- P1 â†’ waits for P2 â†’ waits for P3 â†’ â€¦ â†’ waits for P1

> âœ… If even one condition is prevented â†’ Deadlock cannot occur

## 1ï¸âƒ£ Deadlock Prevention
- Break one of the four conditions.
| Condition        | How to Prevent                |
| ---------------- | ----------------------------- |
| Mutual Exclusion | Make resources sharable       |
| Hold & Wait      | Request all resources at once |
| No Preemption    | Force release of resources    |
| Circular Wait    | Impose resource ordering      |

## 2ï¸âƒ£ Deadlock Avoidance
- Ensure system never enters unsafe state.

1. ğŸ“Œ Bankerâ€™s Algorithm
- Banker's Algorithm is a resource allocation and deadlock avoidance algorithm used in operating systems. It ensures that a system remains in a safe state by carefully allocating resources to processes while avoiding unsafe states that could lead to deadlocks.
![alt text](image-3.png)

## 3ï¸âƒ£ Deadlock Detection 
    - Allow deadlocks
    - Detect using Wait-for Graph
- Recover by:
    - Killing processes
    - Resource preemption
1. If Resources Have a Single Instance
- In this case for Deadlock detection, we can run an algorithm to check for the cycle in the Resource Allocation Graph. The presence of a cycle in the graph is a sufficient condition for deadlock. 
- In the above diagram, resource 1 and resource 2 have single instances. There is a cycle R1 â†’ P1 â†’ R2 â†’ P2. So, Deadlock is Confirmed. 

2. If There are Multiple Instances of Resources
- Detection of the cycle is necessary but not a sufficient condition for deadlock detection, in this case, the system may or may not be in deadlock varies according to different situations.
- For systems with multiple instances of resources, algorithms like Banker's Algorithm can be adapted to periodically check for deadlocks.

## Deadlock Recovery
- A traditional operating system such as Windows doesn't deal with deadlock recovery as it is a time and space-consuming process. Real-time operating systems use Deadlock recovery. 

- Killing The Process: 
- Killing all the processes involved in the deadlock. Killing process one by one. After killing each process check for deadlock again and keep repeating the process till the system recovers from deadlock. Killing all the processes one by one helps a system to break circular wait conditions.

- Resource Preemption: Resources are preempted from the processes involved in the deadlock, and preempted resources are allocated to other processes so that there is a possibility of recovering the system from the deadlock. In this case, the system goes into starvation.

## 4ï¸âƒ£ Ignore Deadlock (Ostrich Algorithm)
- Used in most operating systems like Windows & Linux
- Reason: Deadlocks are rare and handling them is costly

## Memory Management
- Memory Management is the function of the operating system that manages primary memory (RAM) by keeping track of:
- Which parts of memory are in use
    - Which process is using which part
    - Allocating and deallocating memory efficiently.

### ğŸ¯ Objectives of Memory Management
- Efficient use of RAM
- Prevent memory conflicts
- Support multiprogramming
- Provide protection and isolation
- Enable virtual memory

##  Logical Address Space and Physocal Address Space
- The logical address (also called virtual address) is the address generated by the CPU during program
> Logical Address = 0x00401000
- The physical address is the actual location in RAM where data or instructions are stored.
> Physical Address = 0x1A3F2000
> CPU â†’ Logical Address â†’ MMU â†’ Physical Address â†’ RAM
| Feature       | Logical Address | Physical Address |
| ------------- | --------------- | ---------------- |
| Generated by  | CPU             | Memory Unit      |
| Visibility    | Program/User    | Hardware         |
| Also called   | Virtual Address | Real Address     |
| Address Space | Per process     | System-wide      |
| Can be same?  | âŒ (Usually)     | âœ…                |

### ğŸ§± Types of Memory Management
1. ***1ï¸âƒ£ Contiguous Memory Allocation***
- Each process occupies a single continuous block of memory.
- Types:
    - Fixed Partitioning
        - âŒ Internal fragmentation (unused space inside partition)
        - âŒ Limited number of processes
    - Variable Partitioning : 
        - âŒ External fragmentation (free memory scattered)
- ğŸ“Œ Problems:
    - External Fragmentation
    - Limited flexibility.

### Solution of External Fragmentation
1. Compaction
- Moving all the processes toward the top or towards the bottom to make free available memory in a single continuous place is called compaction.

### Memory allocation algorithms : 
- Memory allocation algorithms decide how free memory blocks are assigned to processes in contiguous memory allocation.
- ğŸ§  Main Types of Allocation Algorithms

1. 1ï¸âƒ£ First Fit
- â¡ï¸ Allocates the first block of memory that is large enough.
- ğŸ”¹ How it works:
    - Scan memory from the beginning
    - Allocate the first hole â‰¥ requested size
- âœ… Advantages
    - Fast
    - Simple to implement
- âŒ Disadvantages
    - Causes external fragmentation
    - Memory near the beginning gets filled quickly
- ğŸ“Œ Most commonly used

2. 4ï¸âƒ£ Next Fit
- â¡ï¸ Similar to First Fit, but continues search from **last allocated position**.
- âœ… Advantages
    - Faster than First Fit in some cases
- âŒ Disadvantages
    - Still causes fragmentation

3. 2ï¸âƒ£ Best Fit
- â¡ï¸ Allocates the smallest hole that is sufficient for the request.
- ğŸ”¹ How it works:
    - Search entire memory
    - Choose the smallest suitable block
- âœ… Advantages
    - Minimizes wasted space
- âŒ Disadvantages
    - Slower (searches full list)
    - Creates many tiny unusable holes.

4. 3ï¸âƒ£ Worst Fit
- â¡ï¸ Allocates the largest available block.
- ğŸ”¹ How it works:
    - Chooses the biggest free block
    - Leaves large remaining space
- âœ… Advantages
    - Reduces small unusable fragments
- âŒ Disadvantages
    - Wastes large memory blocks
    - Poor overall utilization.

| Algorithm | Speed    | Fragmentation | Efficiency |
| --------- | -------- | ------------- | ---------- |
| First Fit | Fast     | Medium        | Good       |
| Best Fit  | Slow     | High          | Poor       |
| Worst Fit | Slow     | High          | Poor       |
| Next Fit  | Moderate | Medium        | Fair       |


2. ***2ï¸âƒ£ Non-Contiguous Memory Allocation***
- A process is divided into parts stored in non-adjacent memory locations.
- Types:
    - âœ” Paging
    - âœ” Segmentation
    - âœ” Segmentation with Paging.

## ğŸ“„ Paging
- Memory is divided into fixed-size pages(pagesize = framesize)
- Paging is a memory management technique used by the Operating System to efficiently manage and use RAM by dividing memory into fixed-size blocks.
- Paging divides:
    - Logical (virtual) memory â†’ into pages
    - Physical memory (RAM) â†’ into frames
- Each page is mapped to a frame using a page table.
- ğŸ“Œ Example:
    - Logical address â†’ (page number, offset)
    - Physical address â†’ (frame number, offset)
> To keep track of where each page is stored in memory, the operating system uses a page table. This table shows the connection between the logical page numbers and the physical page frames (actual locations in RAM).

## âœ… Location of Page Table
- The page table is stored in main memory (RAM).
- Every process has its own Page Table and Its base address is stored in a special CPU register called the Page Table Base Register (PTBR).

### ğŸ§  Why Is the Page Table Stored in RAM?
- 1ï¸âƒ£ Because It Can Be Very Large
    - Every process has its own page table
    - Each entry maps a virtual page â†’ physical frame
    - For large processes, page tables can have thousands of entries
- â¡ï¸ Keeping such large tables inside CPU registers or cache is impractical

### Paging usage:
| Area             | Role of Paging         |
| ---------------- | ---------------------- |
| Operating System | Core memory management |
| Virtual Memory   | Allows large programs  |
| Multitasking     | Memory isolation       |
| CPU/MMU          | Address translation    |
| Performance      | Reduces memory waste   |

### âš™ï¸ How Address Translation Works
- CPU generates a logical address
- MMU (Memory Management Unit):
    - Uses PTBR to locate the page table
    - Finds frame number using page number
- Combines frame number + offset â†’ physical address

### ğŸš€ To Improve Speed: TLB
- The naive approach stores the entire page table in main memory. Therefore, for every memory access, the following two memory accesses are required:
    - Access the page table in main memory to get the frame number.
    - Access the actual data in the main memory frame.

#### ğŸ§  TLB (Translation Lookaside Buffer)
![alt text](image-5.png)
- When the CPU generates a virtual address, it first looks up the page number in the TLB.
    - TLB Hit: It is the situation when, the page number is found in the TLB, the corresponding frame number is retrieved instantly.
    - TLB Miss: It is the situation when, the page number is not found in the TLB, the CPU accesses the page table in main memory.

### Advantages:
    - No external fragmentation
    - Easy memory allocation
- Disadvantage:
    - Internal fragmentation

## Problems with Paging
1. ğŸš« 1. Internal Fragmentation
- Pages have fixed size
- Last page of a process may not be fully used
â¡ï¸ Wasted memory inside the page

2. ğŸŒ 2. Page Table Overhead
- Each process needs its own page table
- Large processes â‡’ very large page tables
- Consumes extra memory

3. Slower Memory Access (Two-Level Access)
- For each memory access:
- Access page table
- Access actual memory
- â³ This doubles memory access time
â¡ï¸ Solved partially using TLB

4. TLB Miss Penalty
If page is not found in TLB:
Page table lookup needed
Slower performance

5. The process broke into chunks of page size will be at diff locations and this happens to every function in the program => Overhead.

## Segmentation : 
- Segmentation is a non-contiguous memory management technique where a program is divided into logical units called segments, such as:
    - Code
    - Data
    - Stack
    - Heap
- Each segment represents a logical part of the program, unlike paging which divides memory into fixed-size blocks.
![alt text](image-4.png)

### ğŸ§© Structure of Segmentation
- Each logical address is divided into:
> < Segment Number , Offset >
- Segment Number â†’ identifies the segment
- Offset â†’ location inside the segment

### ğŸ“¦ Segment Table
- Each process has a segment table containing:
    - Base address â†’ starting physical address of the segment
    - Limit â†’ length (size) of the segment
- ğŸ“Œ Address Translation:
    - Physical Address = Base + Offset

### âœ… Advantages of Segmentation
âœ” Matches logical program structure
âœ” Supports protection & sharing
âœ” No internal fragmentation
âœ” Easier memory protection per segment

### âŒ Disadvantages
- âŒ External fragmentation
- âŒ More complex memory management
- âŒ Segment tables consume memory
